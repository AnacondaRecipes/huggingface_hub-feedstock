{% set name = "huggingface_hub" %}
{% set version = "1.2.3" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.org/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz
  sha256: 4ba57f17004fd27bb176a6b7107df579865d4cde015112db59184c51f5602ba7

build:
  number: 0
  script: {{ PYTHON }} -m pip install . --no-deps --no-build-isolation -vv
  skip: true  # [py<38]
  entry_points:
    - huggingface-cli=huggingface_hub.commands.huggingface_cli:main
    - hf=huggingface_hub.cli.hf:main
    - tiny-agents=huggingface_hub.inference._mcp.cli:app

requirements:
  host:
    - python
    - pip
    - setuptools
    - wheel
  run:
    - python
    - filelock
    - fsspec >=2023.5.0
    - hf-xet >=1.2.0,<2.0.0
    - packaging >=20.9
    - pyyaml >=5.1
    - requests
    - tqdm >=4.42.1
    - typing-extensions >=3.7.4.3
    - httpx >=0.23.0,<1
    - shellingham
    - typer-slim
    - typing_extensions >=3.7.4.3
  run_constrained:
    # extras["cli"]
    - inquirerpy >=0.3.4
    # extras["oauth"]
    - authlib >=1.3.2
    # extras["hf_transfer"]
    - hf_transfer>=0.1.4
    # extras["fastai"]
    - fastai >=2.4
    - fastcore >=1.3.27
    # extras["mcp"]
    - mcp >=1.8.0
    # extras["quality"]
    - ruff >=0.9.0
    - mypy >=1.14.1,<1.15.0  # [py==38]
    - mypy >=1.15.0  # [py>=39]
    - libcst >=1.4.0
    # extras["torch"] -> safetensors[torch]
    - torch >=1.10
    - typing_extensions >=4.8.0
    - gradio >=5.0.0
    - hf-xet >=1.1.3,<2.0.0

test:
  imports:
    - huggingface_hub
    - huggingface_hub._commit_api
    - huggingface_hub._commit_scheduler
    - huggingface_hub._local_folder
    - huggingface_hub._login
    - huggingface_hub._oauth
    - huggingface_hub._snapshot_download
    - huggingface_hub._space_api
    - huggingface_hub._upload_large_folder
    - huggingface_hub.cli.auth
    - huggingface_hub.cli.cache
    - huggingface_hub.cli.download
    - huggingface_hub.cli.jobs
    - huggingface_hub.cli.lfs
    - huggingface_hub.cli.repo
    - huggingface_hub.cli.repo_files
    - huggingface_hub.cli.system
    - huggingface_hub.cli.upload
    - huggingface_hub.cli.upload_large_folder
    - huggingface_hub.commands
    - huggingface_hub.commands._cli_utils
    - huggingface_hub.commands.delete_cache
    - huggingface_hub.commands.download
    - huggingface_hub.commands.env
    - huggingface_hub.commands.lfs
    - huggingface_hub.commands.repo
    - huggingface_hub.commands.repo_files
    - huggingface_hub.commands.scan_cache
    - huggingface_hub.commands.tag
    - huggingface_hub.commands.upload
    - huggingface_hub.commands.upload_large_folder
    - huggingface_hub.commands.user
    - huggingface_hub.commands.version
    - huggingface_hub.community
    - huggingface_hub.constants
    - huggingface_hub.dataclasses
    - huggingface_hub.errors
    - huggingface_hub.fastai_utils
    - huggingface_hub.file_download
    - huggingface_hub.hf_api
    - huggingface_hub.hf_file_system
    - huggingface_hub.hub_mixin
    - huggingface_hub.inference_api
    - huggingface_hub.inference._client
    - huggingface_hub.inference._common
    - huggingface_hub.inference._generated
    - huggingface_hub.inference._generated.types
    - huggingface_hub.inference._generated.types.base
    - huggingface_hub.inference._generated.types.chat_completion
    - huggingface_hub.inference._providers
    - huggingface_hub.inference._providers._common
    - huggingface_hub.inference._providers.black_forest_labs
    - huggingface_hub.inference._providers.cohere
    - huggingface_hub.inference._providers.fal_ai
    - huggingface_hub.inference._providers.featherless_ai
    - huggingface_hub.inference._providers.fireworks_ai
    - huggingface_hub.inference._providers.groq
    - huggingface_hub.inference._providers.hf_inference
    - huggingface_hub.inference._providers.hyperbolic
    - huggingface_hub.inference._providers.nebius
    - huggingface_hub.inference._providers.novita
    - huggingface_hub.inference._providers.nscale
    - huggingface_hub.inference._providers.openai
    - huggingface_hub.inference._providers.replicate
    - huggingface_hub.inference._providers.sambanova
    - huggingface_hub.inference._providers.together
    - huggingface_hub.keras_mixin
    - huggingface_hub.lfs
    - huggingface_hub.repocard
    - huggingface_hub.repocard_data
    - huggingface_hub.repository
    - huggingface_hub.serialization
    - huggingface_hub.serialization._base
    - huggingface_hub.serialization._dduf
    - huggingface_hub.serialization._torch
    - huggingface_hub.utils
    - huggingface_hub.utils._auth
    - huggingface_hub.utils._cache_manager
    - huggingface_hub.utils._chunk_utils
    - huggingface_hub.utils._datetime
    - huggingface_hub.utils._deprecation
    - huggingface_hub.utils._dotenv
    - huggingface_hub.utils._git_credential
    - huggingface_hub.utils._headers
    - huggingface_hub.utils._http
    - huggingface_hub.utils._lfs
    - huggingface_hub.utils._pagination
    - huggingface_hub.utils._runtime
    - huggingface_hub.utils._telemetry
    - huggingface_hub.utils._typing
    - huggingface_hub.utils._xet
    - huggingface_hub.utils.endpoint_helpers
    - huggingface_hub.utils.logging
    - huggingface_hub.utils.sha
  requires:
    - pip
    - typer
    # TypeError: Parameter.make_metavar() missing 1 required positional argument: 'ctx'
    - click <8.2
  commands:
    - pip check
    - python -c "from importlib.metadata import version; assert(version('{{ name }}')=='{{ version }}')"
    - huggingface-cli --help
    - hf --help
    - tiny-agents --help
    # Upstream tests took too long and too flaky.

about:
  home: https://github.com/huggingface/huggingface_hub
  summary: Client library to download and publish models, datasets and other repos on the huggingface.co hub
  description: |
    The huggingface_hub is a client library to interact with the Hugging Face Hub. The Hugging Face Hub is a platform with over 35K models, 4K datasets, and 2K demos in which people can easily collaborate in their ML workflows. The Hub works as a central place where anyone can share, explore, discover, and experiment with open-source Machine Learning.

    With huggingface_hub, you can easily download and upload models, datasets, and Spaces. You can extract useful information from the Hub, and do much more. Some example use cases:

    - Downloading and caching files from a Hub repository.
    - Creating repositories and uploading an updated model every few epochs.
    - Extract metadata from all models that match certain criteria (e.g. models for text-classification).
    - List all files from a specific repository.
  license: Apache-2.0
  license_file: LICENSE
  license_family: Apache
  doc_url: https://huggingface.co/docs/hub/index
  dev_url: https://github.com/huggingface/huggingface_hub

extra:
  recipe-maintainers:
    - BastianZim
